{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spotipy in /opt/anaconda3/lib/python3.9/site-packages (2.19.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (2.27.1)\n",
      "Requirement already satisfied: six>=1.15.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.9/site-packages (1.26.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2021.10.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spotipy in /opt/anaconda3/lib/python3.9/site-packages (2.19.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (2.27.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.26.8)\n",
      "Requirement already satisfied: six>=1.15.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install urllib3 --upgrade \n",
    "%pip install requests --upgrade \n",
    "%pip install spotipy --upgrade\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import os\n",
    "import numpy as np\n",
    "import timeit\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from itertools import chain\n",
    "import json\n",
    "\n",
    "os.environ['SPOTIPY_CLIENT_ID'] = '3191e7e8b04e46c1af64f49bcdd020be'\n",
    "os.environ['SPOTIPY_CLIENT_SECRET'] = '88dc925eff0d4006bb6d0b9b2401ac59'\n",
    "auth_manager = SpotifyClientCredentials()\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate artist concentration value for a playlist\n",
    "# low value means high concentration - maybe rename to artist diversity?\n",
    "# input: 2D array of artists for each song\n",
    "# output: real value between 0 and 1\n",
    "def get_artist_div(artists):\n",
    "    unique_artists = len(set(artists))\n",
    "    total_appearances = len(artists)\n",
    "    artist_div = unique_artists / total_appearances\n",
    "    return artist_div\n",
    "\n",
    "MS_IN_DAY = 86400\n",
    "def get_artists_and_dates(uris):\n",
    "    # do the batching above this- here we assume that there are no more than 50 URIs\n",
    "    # i could put an assert statement here but it would slow the code down\n",
    "    # assert(len(uris) <= 50)\n",
    "    artists = {}\n",
    "    dates = {}\n",
    "    tracks = sp.tracks(uris)['tracks']\n",
    "    none_uris = []\n",
    "    for uri, track in zip(uris, tracks):\n",
    "        if track is None:\n",
    "            print(track)\n",
    "            none_uris.append(uri)\n",
    "        else:\n",
    "            artists[uri] = pd.DataFrame(track['artists'])['name'].values.tolist()\n",
    "\n",
    "            date = track['album']['release_date']\n",
    "            while len(date) < 10:\n",
    "                date += '-01'\n",
    "            ms_date = dt.datetime.timestamp(dt.datetime.strptime(date,\"%Y-%m-%d\"))\n",
    "            dates[uri] = ms_date / MS_IN_DAY\n",
    "            \n",
    "    return artists, dates, none_uris\n",
    "\n",
    "# get all audio features for a given playlist\n",
    "def get_playlist_audio_features_batch(playlist_uris):\n",
    "    remainder = len(playlist_uris) % 100\n",
    "    all_features = []\n",
    "    if remainder > 0: \n",
    "        all_features = sp.audio_features(playlist_uris[:remainder])\n",
    "    while remainder < len(playlist_uris):\n",
    "        all_features += sp.audio_features(playlist_uris[remainder:remainder+100])\n",
    "        remainder += 100\n",
    "    \n",
    "    none_uris = []\n",
    "    remainder = len(playlist_uris) % 50\n",
    "    artists, dates = {}, {}\n",
    "    if remainder > 0:\n",
    "        artists, dates, none_uris_iter = get_artists_and_dates(playlist_uris[:remainder])\n",
    "        none_uris += none_uris_iter\n",
    "    while remainder < len(playlist_uris):\n",
    "        next_artists, next_dates, none_uris_iter = get_artists_and_dates(playlist_uris[remainder:remainder+50])\n",
    "\n",
    "        artists.update(next_artists)\n",
    "        dates.update(next_dates)\n",
    "        remainder += 50\n",
    "        none_uris += none_uris_iter\n",
    "\n",
    "    return all_features, artists, dates, none_uris\n",
    "\n",
    "# splits out uris that we have already called the api for\n",
    "# also eliminates duplicate songs within a playlist\n",
    "def deduplicate_uris(playlist_uris, used_tracks_by_uri):\n",
    "    duplicates = np.intersect1d(playlist_uris, np.array(list(used_tracks_by_uri.keys())))\n",
    "    new_uris = np.setdiff1d(playlist_uris, np.array(list(used_tracks_by_uri.keys())))\n",
    "    return duplicates, new_uris\n",
    "\n",
    "# calculate aggregate audio features for a playlist\n",
    "# currently only focused on audio features, I'll deal with artist and release date later\n",
    "def get_playlist_aggregate_features(tracks, used_tracks_by_uri, used_artists_by_uri, used_dates_by_uri):\n",
    "\n",
    "    tracks = pd.DataFrame(tracks)\n",
    "    duplicates, new_uris = deduplicate_uris(tracks['track_uri'], used_tracks_by_uri) # deduplicate here\n",
    "\n",
    "    all_features, artists, dates, none_uris = get_playlist_audio_features_batch(new_uris)\n",
    "\n",
    "    # add duplicates to this playlist for aggregate metric calculation\n",
    "    dup_artists = []\n",
    "    dup_dates = []\n",
    "    if len(duplicates) > 1:\n",
    "        all_features += list(itemgetter(*duplicates)(used_tracks_by_uri))\n",
    "        dup_artists = list(itemgetter(*duplicates)(used_artists_by_uri)) # artists is a dict - update it accordingly\n",
    "        dup_dates = list(itemgetter(*duplicates)(used_dates_by_uri))\n",
    "    elif len(duplicates) == 1:\n",
    "        all_features.append(used_tracks_by_uri[duplicates[0]])\n",
    "        dup_artists = used_artists_by_uri[duplicates[0]]\n",
    "        dup_dates = [used_dates_by_uri[duplicates[0]]]\n",
    "\n",
    "    all_features = pd.DataFrame(all_features)\n",
    "    \n",
    "    # update list of already used tracks\n",
    "    for i, uri in zip(range(len(new_uris)), new_uris):\n",
    "        if uri not in none_uris:\n",
    "            used_tracks_by_uri[uri] = all_features.loc[all_features['uri'] == uri].to_dict('records')[0]\n",
    "            used_artists_by_uri[uri] = artists[uri]\n",
    "            used_dates_by_uri[uri] = dates[uri]\n",
    "\n",
    "\n",
    "    # calculate aggregate features\n",
    "    feature_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    aggregate_features = {}\n",
    "    for feature in feature_list:\n",
    "        all_by_feature = all_features[feature]\n",
    "        aggregate_features[feature] = np.mean(all_by_feature)\n",
    "        aggregate_features[feature+'_var'] = np.var(all_by_feature)\n",
    "\n",
    "    aggregate_features['date'] = np.mean(list(dates.values()) + dup_dates)\n",
    "    aggregate_features['date_var'] = np.var(list(dates.values()) + dup_dates)\n",
    "\n",
    "    if (len(dup_dates) > 1):\n",
    "        dup_artists = list(chain(*dup_artists))\n",
    "    aggregate_features['artist_div'] = get_artist_div(list(chain(*artists.values())) + dup_artists)\n",
    "    return aggregate_features\n",
    "\n",
    "# build the aggregate dataset!\n",
    "def build_dataset_slice(playlists):\n",
    "    aggregate_dataset = []\n",
    "    used_tracks_by_uri = {}\n",
    "    used_artists_by_uri = {}\n",
    "    used_dates_by_uri = {}\n",
    "    for playlist in playlists:\n",
    "        aggregate_dataset.append(get_playlist_aggregate_features(playlist['tracks'], used_tracks_by_uri, used_artists_by_uri, used_dates_by_uri))\n",
    "    return aggregate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_prefix = 'mpd_slice_'\n",
    "slice_zeros = '000_'\n",
    "slice_suffix = '999.json'\n",
    "\n",
    "db_prefix = 'zdb_slice_'\n",
    "db_zeros = '000_'\n",
    "db_suffix = '999.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SLICES = 2\n",
    "for i in range(NUM_SLICES):\n",
    "    print('Starting slice', i)\n",
    "    with open(slice_prefix + i + slice_zeros + i + slice_suffix) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    print('Opened file for slice', i)\n",
    "    dataset_slice = pd.DataFrame(build_dataset_slice(data['playlists']))\n",
    "    print('Built dataset for slice', i)\n",
    "    dataset_slice.to_csv(r''+db_prefix + i + db_zeros + i + db_suffix)\n",
    "    print('Completed slice', i)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
