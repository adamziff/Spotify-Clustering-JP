{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spotipy in /opt/anaconda3/lib/python3.9/site-packages (2.19.0)\n",
      "Requirement already satisfied: six>=1.15.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (2.27.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.9/site-packages (1.26.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (1.26.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spotipy in /opt/anaconda3/lib/python3.9/site-packages (2.19.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (2.27.1)\n",
      "Requirement already satisfied: six>=1.15.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/lib/python3.9/site-packages (from spotipy) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.25.0->spotipy) (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install urllib3 --upgrade \n",
    "%pip install requests --upgrade \n",
    "%pip install spotipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import os\n",
    "import numpy as np\n",
    "import timeit\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from itertools import chain\n",
    "\n",
    "os.environ['SPOTIPY_CLIENT_ID'] = '3191e7e8b04e46c1af64f49bcdd020be'\n",
    "os.environ['SPOTIPY_CLIENT_SECRET'] = '88dc925eff0d4006bb6d0b9b2401ac59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_manager = SpotifyClientCredentials()\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('mpd_slice_0_999.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate artist concentration value for a playlist\n",
    "# low value means high concentration - maybe rename to artist diversity?\n",
    "# input: 2D array of artists for each song\n",
    "# output: real value between 0 and 1\n",
    "def get_artist_div(artists):\n",
    "    #print('get_artist_div')\n",
    "    #print(artists)\n",
    "    unique_artists = len(set(artists))\n",
    "    total_appearances = len(artists)\n",
    "    artist_div = unique_artists / total_appearances\n",
    "    return artist_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_IN_DAY = 86400\n",
    "def get_artists_and_dates(uris):\n",
    "    # do the batching above this- here we assume that there are no more than 50 URIs\n",
    "    # i could put an assert statement here but it would slow the code down\n",
    "    # assert(len(uris) <= 50)\n",
    "    artists = {}\n",
    "    dates = {}\n",
    "    tracks = sp.tracks(uris)['tracks']\n",
    "    none_uris = []\n",
    "    for uri, track in zip(uris, tracks):\n",
    "        if track is None:\n",
    "            print(track)\n",
    "            none_uris.append(uri)\n",
    "        else:\n",
    "            artists[uri] = pd.DataFrame(track['artists'])['name'].values.tolist()\n",
    "            #print(track['artists'])\n",
    "            #print(artists[uri])\n",
    "            date = track['album']['release_date']\n",
    "            while len(date) < 10:\n",
    "                date += '-01'\n",
    "            ms_date = dt.datetime.timestamp(dt.datetime.strptime(date,\"%Y-%m-%d\"))\n",
    "            dates[uri] = ms_date / MS_IN_DAY\n",
    "            \n",
    "    return artists, dates, none_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all audio features for a given playlist\n",
    "def get_playlist_audio_features_batch(playlist_uris):\n",
    "    remainder = len(playlist_uris) % 100\n",
    "    all_features = []\n",
    "    if remainder > 0: \n",
    "        all_features = sp.audio_features(playlist_uris[:remainder])\n",
    "    while remainder < len(playlist_uris):\n",
    "        all_features += sp.audio_features(playlist_uris[remainder:remainder+100])\n",
    "        remainder += 100\n",
    "    \n",
    "    none_uris = []\n",
    "    remainder = len(playlist_uris) % 50\n",
    "    artists, dates = {}, {}\n",
    "    if remainder > 0:\n",
    "        artists, dates, none_uris_iter = get_artists_and_dates(playlist_uris[:remainder])\n",
    "        none_uris += none_uris_iter\n",
    "    while remainder < len(playlist_uris):\n",
    "        next_artists, next_dates, none_uris_iter = get_artists_and_dates(playlist_uris[remainder:remainder+50])\n",
    "\n",
    "        artists.update(next_artists)\n",
    "        dates.update(next_dates)\n",
    "        remainder += 50\n",
    "        none_uris += none_uris_iter\n",
    "\n",
    "    # for i in range(len(all_features)):\n",
    "    #     print(i)\n",
    "    #     print(all_features[i]['uri'])\n",
    "    #     print(artists.keys()[i])\n",
    "    return all_features, artists, dates, none_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits out uris that we have already called the api for\n",
    "# also eliminates duplicate songs within a playlist\n",
    "def deduplicate_uris(playlist_uris, used_tracks_by_uri):\n",
    "    duplicates = np.intersect1d(playlist_uris, np.array(list(used_tracks_by_uri.keys())))\n",
    "    new_uris = np.setdiff1d(playlist_uris, np.array(list(used_tracks_by_uri.keys())))\n",
    "    return duplicates, new_uris#, count_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure artists and dates get added to used_tracks_by_uri entries\n",
    "# \n",
    "\n",
    "# calculate aggregate audio features for a playlist\n",
    "# currently only focused on audio features, I'll deal with artist and release date later\n",
    "def get_playlist_aggregate_features(tracks, used_tracks_by_uri, used_artists_by_uri, used_dates_by_uri):\n",
    "\n",
    "    tracks = pd.DataFrame(tracks)\n",
    "    duplicates, new_uris = deduplicate_uris(tracks['track_uri'], used_tracks_by_uri) # deduplicate here\n",
    "\n",
    "    all_features, artists, dates, none_uris = get_playlist_audio_features_batch(new_uris)\n",
    "\n",
    "    # add duplicates to this playlist for aggregate metric calculation\n",
    "    dup_artists = []\n",
    "    dup_dates = []\n",
    "    if len(duplicates) > 1:\n",
    "        all_features += list(itemgetter(*duplicates)(used_tracks_by_uri))\n",
    "        dup_artists = list(itemgetter(*duplicates)(used_artists_by_uri)) # artists is a dict - update it accordingly\n",
    "        dup_dates = list(itemgetter(*duplicates)(used_dates_by_uri))\n",
    "    elif len(duplicates) == 1:\n",
    "        all_features.append(used_tracks_by_uri[duplicates[0]])\n",
    "        dup_artists = used_artists_by_uri[duplicates[0]]\n",
    "        print(used_dates_by_uri[duplicates[0]])\n",
    "        dup_dates = list(used_dates_by_uri[duplicates[0]])\n",
    "\n",
    "    #print(all_features[19])\n",
    "    all_features = pd.DataFrame(all_features)\n",
    "\n",
    "    # option 1 - add artists and dates into all_features\n",
    "    # option 2 - keep artists and dates separate and do a used_artists_by_uri dict\n",
    "    # all_features['artists'] = artists.values()\n",
    "    # all_features['date'] = dates.values()\n",
    "    # for row in all_features:\n",
    "    #     print(row['uri'])\n",
    "    #     print(row['artists'])\n",
    "    #     print(artists[row['uri']])\n",
    "    #     print()\n",
    "\n",
    "\n",
    "    # all_features.set_index(all_features['uri'])\n",
    "    # print(all_features)\n",
    "    # all_features = all_features.to_dict('index')\n",
    "    # print(all_features)\n",
    "    \n",
    "    # update list of already used tracks\n",
    "    for i, uri in zip(range(len(new_uris)), new_uris):\n",
    "        if uri not in none_uris:\n",
    "            used_tracks_by_uri[uri] = all_features.loc[all_features['uri'] == uri].to_dict('records')[0]\n",
    "            #print(used_tracks_by_uri[uri])\n",
    "            #artist_dict[uri] = artists[uri].values\n",
    "            #dates_dict[uri] = dates[uri]\n",
    "            #print(used_tracks_by_uri[uri])\n",
    "            #print(artists[uri])\n",
    "            #print(artists[uri].to_numpy())\n",
    "            used_artists_by_uri[uri] = artists[uri] #.insert(1, 'artists', artists[uri].to_numpy(), True)\n",
    "            used_dates_by_uri[uri] = dates[uri] #.insert(1, 'date', dates[uri], True)\n",
    "            #print(used_tracks_by_uri[uri]['artists'])\n",
    "\n",
    "            # print(all_features.loc[all_features['uri'] == uri])\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    #print(artists)\n",
    "    #all_features = pd.DataFrame(all_features)\n",
    "    #print(all_features['artists'])\n",
    "    #all_features[weird_uri]['artists'] = 'uh'\n",
    "    #artists = np.concatenate(all_features['artists']).ravel()\n",
    "    #print('yay?')\n",
    "\n",
    "\n",
    "    # #print(all_features[19])\n",
    "    # all_features = pd.DataFrame(all_features)\n",
    "    #print(all_features)\n",
    "    #print(all_features['artists'])\n",
    "    #artists_list = np.concatenate(all_features['artists']).ravel()# + artists.values()\n",
    "\n",
    "\n",
    "    # calculate aggregate features\n",
    "    feature_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    aggregate_features = {}\n",
    "    for feature in feature_list:\n",
    "        all_by_feature = all_features[feature]\n",
    "        aggregate_features[feature] = np.mean(all_by_feature)\n",
    "        aggregate_features[feature+'_var'] = np.var(all_by_feature)\n",
    "\n",
    "    #print(list(chain(*artists.values())))\n",
    "    aggregate_features['date'] = np.mean(list(dates.values()) + dup_dates)\n",
    "    aggregate_features['date_var'] = np.var(list(dates.values()) + dup_dates)\n",
    "    aggregate_features['artist_div'] = get_artist_div(list(chain(*artists.values())) + list(chain(*dup_artists)))\n",
    "    return aggregate_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the aggregate dataset!\n",
    "def build_dataset(playlists):\n",
    "    aggregate_dataset = []\n",
    "    used_tracks_by_uri = {}\n",
    "    used_artists_by_uri = {}\n",
    "    used_dates_by_uri = {}\n",
    "    for playlist in playlists:\n",
    "        aggregate_dataset.append(get_playlist_aggregate_features(playlist['tracks'], used_tracks_by_uri, used_artists_by_uri, used_dates_by_uri))\n",
    "    return aggregate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f1/06_sb4pj60b3_t6f1ptwvv840000gn/T/ipykernel_30836/1270547520.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#[497:498] has a uri that returns None from the API in it, uri 19 in the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# somewhere after it has a mean of empty slice situation happening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playlists'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/f1/06_sb4pj60b3_t6f1ptwvv840000gn/T/ipykernel_30836/3192869174.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(playlists)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mused_dates_by_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mplaylist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplaylists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0maggregate_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_playlist_aggregate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tracks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_tracks_by_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_artists_by_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_dates_by_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maggregate_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f1/06_sb4pj60b3_t6f1ptwvv840000gn/T/ipykernel_30836/3789681355.py\u001b[0m in \u001b[0;36mget_playlist_aggregate_features\u001b[0;34m(tracks, used_tracks_by_uri, used_artists_by_uri, used_dates_by_uri)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mall_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mused_tracks_by_uri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdup_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mused_artists_by_uri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdup_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mused_dates_by_uri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#print(all_features[19])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "#[497:498] has a uri that returns None from the API in it, uri 19 in the list\n",
    "# somewhere after it has a mean of empty slice situation happening\n",
    "dataset = pd.DataFrame(build_dataset(data['playlists'][0:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(r'csvdata_nodup_10.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.4190453339997475\n",
      "Time: 3.8613711670004705\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"float\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f1/06_sb4pj60b3_t6f1ptwvv840000gn/T/ipykernel_30836/3205279633.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'build_dataset(data[\\'playlists\\'][:i])'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from __main__ import build_dataset, data, i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/timeit.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/timeit.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m/var/folders/f1/06_sb4pj60b3_t6f1ptwvv840000gn/T/ipykernel_30836/3192869174.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(playlists)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mused_dates_by_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mplaylist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplaylists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0maggregate_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_playlist_aggregate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tracks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_tracks_by_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_artists_by_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_dates_by_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maggregate_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/f1/06_sb4pj60b3_t6f1ptwvv840000gn/T/ipykernel_30836/3017293987.py\u001b[0m in \u001b[0;36mget_playlist_aggregate_features\u001b[0;34m(tracks, used_tracks_by_uri, used_artists_by_uri, used_dates_by_uri)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m#print(list(chain(*artists.values())))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0maggregate_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdup_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0maggregate_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_var'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdup_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0maggregate_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'artist_div'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_artist_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdup_artists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"float\") to list"
     ]
    }
   ],
   "source": [
    "times = [1, 10, 100, 1000]\n",
    "for i in times:\n",
    "    t = timeit.Timer('build_dataset(data[\\'playlists\\'][:i])', 'from __main__ import build_dataset, data, i')\n",
    "    print('Time: ' + str(t.timeit(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#207 dates mean of empty slice"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
