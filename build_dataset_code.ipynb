{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "#with zipfile.ZipFile('spotify_million_playlist_dataset.zip', 'r') as zip_ref:\n",
    "    #zip_ref.extractall('Spotify MPD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install urllib3 --upgrade \n",
    "%pip install requests --upgrade \n",
    "%pip install spotipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import os\n",
    "import numpy as np\n",
    "import timeit\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "os.environ['SPOTIPY_CLIENT_ID'] = '3191e7e8b04e46c1af64f49bcdd020be'\n",
    "os.environ['SPOTIPY_CLIENT_SECRET'] = '88dc925eff0d4006bb6d0b9b2401ac59'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_manager = SpotifyClientCredentials()\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('mpd_slice_0_999.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# V3 - BATCH V2 ###################\n",
    "# TODO: TIME THIS TO SEE IF IT WORKS\n",
    "# TODO: CALCULATE THE OTHER TWO METRICS\n",
    "# TODO: CLEAN UP DATES (divide by something, make the values way smaller and potentially all positive)\n",
    "# TODO: WHY IS tempo_var SO HIGH?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all track URIs for all playlists\n",
    "def get_all_track_URIs(playlists):\n",
    "    uri_list = []\n",
    "    for playlist in playlists:\n",
    "        playlist = pd.DataFrame(playlist)\n",
    "        #print(playlist)\n",
    "        uri_list.append(playlist['track_uri'])\n",
    "        #for tracks in playlist['tracks']:\n",
    "            #uri_list += tracks['track_uri']\n",
    "    #print(np.shape(uri_list))\n",
    "    return uri_list\n",
    "    #data['playlists'][0]['tracks'][i]['track_uri']\n",
    "    #print(uri_list)\n",
    "#all_uris = get_all_track_URIs(data['playlists'])\n",
    "#print(all_uris[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = pd.DataFrame(data['playlists'])\n",
    "#print(pd.DataFrame(pd_data['tracks'][0])['track_uri'])\n",
    "print(pd.DataFrame(pd_data['tracks']))\n",
    "print(np.shape(pd_data['tracks']))\n",
    "all_uri_attempt = pd.DataFrame(pd_data['tracks'])['track_uri']\n",
    "print(np.shape(all_uri_attempt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(pd_data['tracks'][0][0].values())[2])\n",
    "# uri index in track object is 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all audio features\n",
    "def get_all_audio_features_batch(playlist_uris):\n",
    "    all_features = []\n",
    "    for playlist in playlist_uris:\n",
    "        remainder = len(playlist) % 100\n",
    "        if remainder > 0: \n",
    "            all_features.append(sp.audio_features(playlist[:remainder]))\n",
    "        while remainder < len(playlist):\n",
    "            #print(all_features[-1])\n",
    "            all_features[-1] += sp.audio_features(playlist[remainder:remainder+100])\n",
    "            remainder += 100\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all aggregate audio features, build the dataset\n",
    "def get_all_aggregate_features(playlists):\n",
    "    all_playlist_uris = get_all_track_URIs(playlists)\n",
    "    all_features = get_all_audio_features_batch(all_playlist_uris)\n",
    "    feature_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    all_aggregate_features = []\n",
    "    for playlist in all_features:\n",
    "        playlist = pd.DataFrame(playlist)\n",
    "        aggregate_features = {}\n",
    "        for feature in feature_list:\n",
    "            #all_by_feature = [track[feature] for track in all_features]\n",
    "            all_by_feature = playlist[feature]\n",
    "            aggregate_features[feature] = np.mean(all_by_feature)\n",
    "            aggregate_features[feature+'_var'] = np.var(all_by_feature)\n",
    "        all_aggregate_features.append(aggregate_features)\n",
    "    #print(np.shape(aggregate_features))\n",
    "    return all_aggregate_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = pd.DataFrame(data['playlists'])\n",
    "t = timeit.Timer('get_all_aggregate_features(pd_data[\\'tracks\\'][0:100])', 'from __main__ import get_all_aggregate_features, pd_data')\n",
    "print('V3: ' + str(t.timeit(1)))\n",
    "t = timeit.Timer('build_dataset_v2(data[\\'playlists\\'][0:100])', 'from __main__ import build_dataset_v2, data')\n",
    "print('V2: ' + str(t.timeit(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = pd.DataFrame(data['playlists'])\n",
    "dataset = get_all_aggregate_features(pd_data['tracks'][0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### VERSION 1 #######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all track URIs for a given playlist\n",
    "def get_uris_for_playlist(tracks):\n",
    "    uri_list = []\n",
    "    for track in tracks:\n",
    "        uri_list.append(track['track_uri'])\n",
    "    return uri_list\n",
    "#playlist_uris = get_uris_for_playlist(data['playlists'][0])\n",
    "\n",
    "# get all audio features for a given playlist\n",
    "def get_playlist_audio_features(tracks):\n",
    "    uri_list = get_uris_for_playlist(tracks)\n",
    "    all_features = []\n",
    "    for uri in uri_list:\n",
    "        track_features = sp.audio_features(uri) # consider batching this\n",
    "        # this will have unnecessary features, will be removed in aggregation step\n",
    "        all_features.append(track_features[0])\n",
    "    #print(all_features[0])\n",
    "    return all_features\n",
    "\n",
    "# calculate aggregate audio features for a playlist\n",
    "# currently only focused on audio features, I'll deal with artist and release date later\n",
    "def get_playlist_aggregate_features(tracks):\n",
    "    all_features = get_playlist_audio_features(tracks)\n",
    "    #print(all_features[0:5])\n",
    "    feature_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    aggregate_features = {}\n",
    "    for feature in feature_list:\n",
    "        all_by_feature = []\n",
    "        for track in all_features:\n",
    "            #print(track)\n",
    "            all_by_feature.append(track[feature])\n",
    "        aggregate_features[feature] = np.mean(all_by_feature)\n",
    "        aggregate_features[feature+'_var'] = np.var(all_by_feature)\n",
    "    return aggregate_features\n",
    "\n",
    "# build the aggregate dataset!\n",
    "def build_dataset(playlists):\n",
    "    aggregate_dataset = []\n",
    "    for playlist in playlists:\n",
    "        aggregate_dataset.append(get_playlist_aggregate_features(playlist['tracks']))\n",
    "    return aggregate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all audio features for a given playlist\n",
    "def get_playlist_audio_features_v2(tracks):\n",
    "    all_features = []\n",
    "    for track in tracks:\n",
    "        track_features = sp.audio_features(track['track_uri']) # consider batching this\n",
    "        # this will have unnecessary features, will be removed in aggregation step\n",
    "        all_features.append(track_features[0])\n",
    "    #print(all_features[0])\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## V2 - BATCH V1 ######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all audio features for a given playlist\n",
    "def get_playlist_audio_features_batch(tracks):\n",
    "    tracks = pd.DataFrame(tracks)\n",
    "    playlist_uris = tracks['track_uri']\n",
    "\n",
    "    remainder = len(tracks) % 100\n",
    "    all_features = []\n",
    "    if remainder > 0: \n",
    "        all_features = sp.audio_features(playlist_uris[:remainder])\n",
    "    while remainder < len(tracks):\n",
    "        all_features += sp.audio_features(playlist_uris[remainder:remainder+100])\n",
    "        remainder += 100\n",
    "    \n",
    "    remainder = len(tracks) % 50\n",
    "    artists, dates = [], []\n",
    "    if remainder > 0:\n",
    "        artists, dates = get_artists_and_dates(playlist_uris[:remainder])\n",
    "    while remainder < len(tracks):\n",
    "        next_artists, next_dates = get_artists_and_dates(playlist_uris[remainder:remainder+50])\n",
    "        artists += next_artists\n",
    "        dates += next_dates\n",
    "        remainder += 50\n",
    "    return all_features, artists, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate aggregate audio features for a playlist\n",
    "# currently only focused on audio features, I'll deal with artist and release date later\n",
    "def get_playlist_aggregate_features_v2(tracks):\n",
    "    all_features, artists, dates = get_playlist_audio_features_batch(tracks)\n",
    "    all_features = pd.DataFrame(all_features)\n",
    "    feature_list = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    aggregate_features = {}\n",
    "    for feature in feature_list:\n",
    "        #all_by_feature = [track[feature] for track in all_features]\n",
    "        all_by_feature = all_features[feature]\n",
    "        aggregate_features[feature] = np.mean(all_by_feature)\n",
    "        aggregate_features[feature+'_var'] = np.var(all_by_feature)\n",
    "    aggregate_features['date'] = np.mean(dates)\n",
    "    aggregate_features['date_var'] = np.var(dates)\n",
    "    # calculate artist index - right now doesn't account for featured artists\n",
    "    # can account for featured artists using data from sp.tracks() method\n",
    "    #aggregate_features['artist_conc'] = num_artists / len(tracks)\n",
    "    aggregate_features['artist_conc'] = get_artist_conc(artists)\n",
    "    return aggregate_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the aggregate dataset!\n",
    "def build_dataset_v2(playlists):\n",
    "    aggregate_dataset = []\n",
    "    for playlist in playlists:\n",
    "        aggregate_dataset.append(get_playlist_aggregate_features_v2(playlist['tracks']))\n",
    "    return aggregate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist1 = tracks_test\n",
    "playlist1_df = pd.DataFrame(playlist1)\n",
    "\n",
    "def test_playlist1(playlist1):\n",
    "    uris = []\n",
    "    for track in playlist1:\n",
    "        uris.append(track['track_uri'])\n",
    "    return uris\n",
    "\n",
    "\n",
    "def test_playlist1_df(playlist1_df):\n",
    "    return playlist1_df['track_uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = timeit.Timer('test = test_playlist1(playlist1)', 'from __main__ import test_playlist1, playlist1')\n",
    "print('no DF: ' + str(t.timeit(1)))\n",
    "t = timeit.Timer('test = test_playlist1_df(playlist1_df)', 'from __main__ import test_playlist1_df, playlist1_df')\n",
    "print('DF: ' + str(t.timeit(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_prep = [playlist['tracks'] for playlist in data['playlists'][:20]]\n",
    "tracks_test = []\n",
    "for playlist in tracks_prep:\n",
    "    for track in playlist:\n",
    "        tracks_test.append(track)\n",
    "print(np.shape(tracks_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = timeit.Timer('get_playlist_audio_features(tracks_test)', 'from __main__ import get_playlist_audio_features, tracks_test')\n",
    "print('V1: ' + str(t.timeit(1)))\n",
    "t = timeit.Timer('get_playlist_audio_features_v2(tracks_test)', 'from __main__ import get_playlist_audio_features_v2, tracks_test')\n",
    "print('V2: ' + str(t.timeit(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset_v2(data['playlists'][434:437])\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp.audio_features(tracks=[]) # max 100 ids\n",
    "# sp.tracks(tracks=[], market=None) # max 50 ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artists_and_dates(uris):\n",
    "    # do the batching above this- here we assume that there are no more than 50 URIs\n",
    "    # i could put an assert statement here but it would slow the code down\n",
    "    # assert(len(uris) <= 50)\n",
    "    artists = []\n",
    "    dates = []\n",
    "    #old_dates = []\n",
    "    tracks = sp.tracks(uris)['tracks']\n",
    "    #print(tracks)\n",
    "    #albums = tracks['album']\n",
    "    #print(tracks['artists'][0])\n",
    "    # TODO: FIGURE OUT HOW TO DO THIS MORE EFFICIENTLY\n",
    "    #print(len(tracks))\n",
    "    for track in tracks:\n",
    "        if track is None:\n",
    "            print(track)\n",
    "        else:\n",
    "            for artist in track['artists']:\n",
    "                artists.append(artist['name'])\n",
    "            date = track['album']['release_date']\n",
    "            while len(date) < 10:\n",
    "                date += '-01'\n",
    "            dates.append(dt.datetime.timestamp(dt.datetime.strptime(date,\"%Y-%m-%d\"))) # some dates are negative bc pre-1970, does that matter?\n",
    "        #old_dates.append(track['album']['release_date'])\n",
    "    #print('############################################')\n",
    "    #print(artists)\n",
    "    #print(len(artists))\n",
    "    #print('############################################')\n",
    "    #print(dates)\n",
    "    #print(old_dates)\n",
    "    return artists, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['playlists'][497:498])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = timeit.Timer('build_dataset(data[\\'playlists\\'][0:3])', 'from __main__ import build_dataset, data')\n",
    "#print('V1: ' + str(t.timeit(1)))\n",
    "#print(data['playlists'][0:4])\n",
    "t = timeit.Timer('build_dataset_v2(data[\\'playlists\\'][:100])', 'from __main__ import build_dataset_v2, data')\n",
    "print('V2: ' + str(t.timeit(1)))\n",
    "# right now it's 4.6 days for the whole thing\n",
    "# 400 seconds for the whole dataset\n",
    "# 35 seconds ish for the first hundred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate artist concentration value for a playlist\n",
    "# low value means high concentration - maybe rename to artist diversity?\n",
    "# input: 2D array of artists for each song\n",
    "# output: real value between 0 and 1\n",
    "def get_artist_conc(artists):\n",
    "    unique_artists = len(set(artists))\n",
    "    total_appearances = len(artists)\n",
    "    artist_conc = unique_artists / total_appearances\n",
    "    return artist_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset_v2(data['playlists'][1:2])\n",
    "#print(dataset)\n",
    "#data['playlists'][434:435][0]['num_artists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tracks = sp.tracks(pd.DataFrame(tracks_test)['track_uri'][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.DataFrame(first_tracks['tracks'])\n",
    "albums = pd.DataFrame(tracks['album'])\n",
    "#print(albums['release_date'])\n",
    "print(pd.DataFrame(albums['album']))\n",
    "print(np.shape(albums))\n",
    "\n",
    "#print(pd.DataFrame(pd.DataFrame(first_tracks['tracks'])['album'])[0:2]['release_date'])\n",
    "#print(type(pd.DataFrame(first_tracks['tracks'])['album'][0]['release_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(pd.DataFrame(first_tracks['tracks'])['artists'][0])['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_str = 'mpd_slice_'\n",
    "num1_str = '0_'\n",
    "num2_str = '999.json'\n",
    "file_str = name_str + num1_str + num2_str\n",
    "print(file_str)\n",
    "num1_str = '000_'\n",
    "dataset = []\n",
    "for i in range(1,1000):\n",
    "    file_str = name_str + str(i) + num1_str + str(i) + num2_str\n",
    "    print(file_str)\n",
    "    with open(file_str) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    dataset += build_dataset_v2(data['playlists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a2c081ab79233eef81851a0f915c54ec256343befc026786e3e18bde51bf24c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
